import { NextRequest, NextResponse } from 'next/server';
import { GoogleGenerativeAI } from '@google/generative-ai';

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY!);

export async function POST(request: NextRequest) {
  try {
    const { messages, sketchImage } = await request.json();

    console.log('üí¨ Chat request:', { 
      messageCount: messages.length, 
      hasSketch: !!sketchImage 
    });

    const model = genAI.getGenerativeModel({ model: 'gemini-flash-latest' });

    // Filtrer les messages pour garder seulement les messages utilisateur et mod√®le (exclure le premier message d'accueil)
    const userMessages = messages.filter((msg: any) => msg.role === 'user');
    const modelMessages = messages.filter((msg: any) => msg.role === 'assistant' && msg.content !== messages[0].content);

    // Construire l'historique de conversation pour Gemini (exclure le dernier message user)
    const historyMessages = messages.slice(1, -1); // Ignorer le premier (accueil) et le dernier (√† envoyer)
    
    const chat = model.startChat({
      history: historyMessages
        .filter((msg: any) => msg.role !== 'assistant' || msg.content !== messages[0].content) // Exclure message d'accueil
        .map((msg: any) => ({
          role: msg.role === 'user' ? 'user' : 'model',
          parts: [{ text: msg.content }],
        })),
      generationConfig: {
        temperature: 0.7,
        topK: 20,
        topP: 0.95,
        maxOutputTokens: 2048,
      },
    });

    // Dernier message de l'utilisateur
    const lastMessage = messages[messages.length - 1];
    let prompt = lastMessage.content;

    // Ajouter le contexte syst√®me au premier message utilisateur
    const isFirstUserMessage = userMessages.length === 1;
    
    if (isFirstUserMessage && !sketchImage) {
      // Premier message sans sketch : ajouter le contexte
      prompt = `[R√àGLE STRICTE : R√©ponds en MAXIMUM 20 mots. UNE question courte, pas de tableaux, pas d'explications.]

Message : ${prompt}

Ta r√©ponse (max 20 mots) :`;
    }

    // Si c'est une demande de g√©n√©ration de fiche
    if (prompt.toLowerCase().includes('g√©n√®re') || prompt.toLowerCase().includes('fiche')) {
      prompt = `${prompt}

G√©n√®re une fiche produit structur√©e au format JSON avec cette structure EXACTE :
{
  "productName": "Nom du produit",
  "category": "Cat√©gorie (mobilier/√©lectronique/accessoire/etc.)",
  "description": "Description d√©taill√©e du produit (2-3 phrases)",
  "targetAudience": "Public cible",
  "keyFeatures": ["Caract√©ristique 1", "Caract√©ristique 2", "Caract√©ristique 3"],
  "style": "Style visuel (moderne/classique/minimaliste/industriel/etc.)",
  "materials": ["Mat√©riau 1", "Mat√©riau 2"],
  "colors": ["Couleur primaire", "Couleur secondaire"],
  "dimensions": "Dimensions approximatives",
  "usageContext": "Contexte d'utilisation"
}

R√©ponds UNIQUEMENT avec le JSON, sans texte avant ou apr√®s.`;
    } else if (!isFirstUserMessage && !prompt.toLowerCase().includes('g√©n√®re') && !prompt.toLowerCase().includes('fiche')) {
      // Messages interm√©diaires : forcer la bri√®vet√©
      prompt = `[R√àGLE : Max 25 mots. UNE question courte. Pas de tableaux, pas de listes.]

${prompt}

Ta r√©ponse (max 25 mots) :`;
    }

    let result;

    // Si sketch fourni, l'inclure dans l'analyse avec le contexte complet
    if (sketchImage && lastMessage.role === 'user') {
      // Convertir base64 en format Gemini
      const imageData = sketchImage.split(',')[1]; // Retirer "data:image/...;base64,"
      
      // Construire un prompt contextualis√© pour l'analyse du sketch
      const sketchPrompt = `[R√àGLE : R√©ponds en MAXIMUM 25 mots. Analyse rapide + UNE question courte. Pas de tableaux.]

Sketch du produit : ${prompt}

Ta r√©ponse (max 25 mots) :`;

      result = await model.generateContent([
        {
          inlineData: {
            mimeType: 'image/png',
            data: imageData,
          },
        },
        { text: sketchPrompt },
      ]);
    } else {
      // Dialogue texte uniquement
      result = await chat.sendMessage(prompt);
    }

    const response = result.response;
    const text = response.text();

    console.log('‚úÖ Gemini response:', text.substring(0, 200) + '...');

    return NextResponse.json({
      success: true,
      message: text,
    });

  } catch (error: any) {
    console.error('‚ùå Chat API error:', error);
    return NextResponse.json(
      { 
        success: false, 
        error: error.message || 'Failed to process chat message' 
      },
      { status: 500 }
    );
  }
}
